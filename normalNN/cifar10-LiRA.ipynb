{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32827\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/32827/Documents/GitHub/BackdoorBox/')\n",
    "import core\n",
    "# import LIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_dataset\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import DatasetFolder, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss,Softmax\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets and follow the default data augmentation in the original paper\n",
    "transform_train = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    train=True,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   29    30    35 ... 49941 49992 49994]\n",
      "[    4     5    32 ... 49993 49998 49999]\n",
      "[    6    13    18 ... 49987 49991 49995]\n",
      "[    9    17    21 ... 49979 49982 49983]\n",
      "[29497  4079 33087 ... 30213 36230 31134]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "trainset.targets = np.array(trainset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(trainset.targets == targets)[0]\n",
    "    print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 1000))\n",
    "idx = idx.astype(int)\n",
    "print(idx)\n",
    "trainset.data = trainset.data[idx]\n",
    "trainset.targets = trainset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_test,\n",
    "    target_transform=None,\n",
    "    train=False,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "testset.targets = np.array(testset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(testset.targets == targets)[0]\n",
    "    # print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 100))\n",
    "idx = idx.astype(int)\n",
    "# print(idx)\n",
    "testset.data = testset.data[idx]\n",
    "testset.targets = testset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(3)\n",
    "    ansatz = RealAmplitudes(3, reps=1)\n",
    "    qc = QuantumCircuit(3)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    parity = lambda x: \"{:b}\".format(x).count(\"1\") % 4  # optional interpret function\n",
    "    output_shape = 4  # parity = 0, 1\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        interpret=parity,\n",
    "        output_shape=output_shape,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self,qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(84,4)  # 1-dimensional output from QNN\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc4 = Linear(4,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "classifier_model = Net(qnn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = {\n",
    "    'device': 'GPU',\n",
    "    'CUDA_VISIBLE_DEVICES': '1',\n",
    "    'GPU_num': 1,\n",
    "\n",
    "    'benign_training': False,\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 8,\n",
    "\n",
    "    'lr': 0.0001,\n",
    "    'lr_atk': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    \n",
    "    'epochs': 5,\n",
    "    'train_epoch': 1,\n",
    "    'cls_test_epoch': 5,\n",
    "\n",
    "\n",
    "    'tune_test_epochs': 1,\n",
    "    'tune_test_lr': 0.0001,\n",
    "    'tune_momentum': 0.9,\n",
    "    'tune_weight_decay': 5e-4,\n",
    "    'tune_test_epoch_interval': 1,\n",
    "\n",
    "    'schedulerC_lambda': 0.1,\n",
    "    'schedulerC_milestones': '50,100,150,200',\n",
    "\n",
    "    'log_iteration_interval': 100,\n",
    "    'test_epoch_interval': 10,\n",
    "    'save_epoch_interval': 10,\n",
    "\n",
    "    'pretrain':\"./models/normal-cifar10_mdl.pt\",\n",
    "    'save_dir': 'experiments',\n",
    "    'experiment_name': 'train_poison_DataFolder_CIFAR10_LIRA'\n",
    "    # 'num_workers' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIRA = core.LIRA(\n",
    "    dataset_name=\"ncifar10\",\n",
    "    train_dataset=trainset,\n",
    "    test_dataset=testset,\n",
    "    model=classifier_model, #core.models.vgg11(num_classes=10), #core.models.ResNet(18),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    y_target=1,\n",
    "    eps=0.001,\n",
    "    alpha=0.5,\n",
    "    tune_test_eps=0.0001,\n",
    "    tune_test_alpha=0.5,\n",
    "    best_threshold=0.1,\n",
    "    schedule=schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain activated\n",
      "This machine has 1 cuda devices, and use 1 of them to train.\n",
      "Total train samples: 4000\n",
      "Total test samples: 400\n",
      "Batch size: 4\n",
      "iteration every epoch: 1000\n",
      "Initial learning rate: 0.0001\n",
      "\n",
      "[2024-03-11_09:24:02] Train [1] Loss: clean 1.3728 poison 7.0726 total 4.2227 Tri 1.4261\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:24:12] Top-1 correct / Total: 154/400, Top-1 accuracy: 0.385, Top-3 correct / Total: 154/400, Top-3 accuracy: 0.385 time: 47.455097913742065\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:24:12] Top-1 correct / Total: 325/400, Top-1 accuracy: 0.8125, Top-3 correct / Total: 325/400, Top-3 accuracy: 0.8125, time: 47.4560980796814\n",
      "\n",
      "[2024-03-11_09:24:52] Train [2] Loss: clean 0.8518 poison 4.2154 total 2.5336 Tri 1.4258\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:25:02] Top-1 correct / Total: 168/400, Top-1 accuracy: 0.42, Top-3 correct / Total: 168/400, Top-3 accuracy: 0.42 time: 97.50712871551514\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:25:02] Top-1 correct / Total: 317/400, Top-1 accuracy: 0.7925, Top-3 correct / Total: 317/400, Top-3 accuracy: 0.7925, time: 97.50812888145447\n",
      "\n",
      "[2024-03-11_09:25:21] Train [3] Loss: clean 0.7843 poison 3.7618 total 2.2731 Tri 1.4142\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:25:31] Top-1 correct / Total: 171/400, Top-1 accuracy: 0.4275, Top-3 correct / Total: 171/400, Top-3 accuracy: 0.4275 time: 126.05535292625427\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:25:31] Top-1 correct / Total: 315/400, Top-1 accuracy: 0.7875, Top-3 correct / Total: 315/400, Top-3 accuracy: 0.7875, time: 126.0563530921936\n",
      "\n",
      "[2024-03-11_09:26:02] Train [4] Loss: clean 0.7619 poison 3.8355 total 2.2987 Tri 1.4066\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:26:07] Top-1 correct / Total: 170/400, Top-1 accuracy: 0.425, Top-3 correct / Total: 170/400, Top-3 accuracy: 0.425 time: 161.55963158607483\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:26:07] Top-1 correct / Total: 317/400, Top-1 accuracy: 0.7925, Top-3 correct / Total: 317/400, Top-3 accuracy: 0.7925, time: 161.55963158607483\n",
      "\n",
      "[2024-03-11_09:26:23] Train [5] Loss: clean 0.7419 poison 4.0530 total 2.3974 Tri 1.4215\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:26:43] Top-1 correct / Total: 162/400, Top-1 accuracy: 0.405, Top-3 correct / Total: 162/400, Top-3 accuracy: 0.405 time: 198.04391741752625\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:26:43] Top-1 correct / Total: 324/400, Top-1 accuracy: 0.81, Top-3 correct / Total: 324/400, Top-3 accuracy: 0.81, time: 198.04391741752625\n",
      "\n",
      "[2024-03-11_09:26:48] Finetune [1] Loss: clean 1.2137 poison 0.6726 total 0.9432\n",
      "\n",
      "tensor([[-4.3898e-01,  1.0002e+00, -5.5443e-04, -2.1158e+00],\n",
      "        [-8.1195e-01,  1.4965e+00, -4.1440e-01, -1.3574e+00],\n",
      "        [ 1.6655e+00,  1.7704e+00, -8.9391e-01, -1.3248e+00],\n",
      "        ...,\n",
      "        [-3.2352e+00,  3.6241e+00, -2.2596e+00,  1.4266e+00],\n",
      "        [-1.5470e+00,  3.8383e-02,  4.6694e-02, -3.9329e-02],\n",
      "        [-1.9615e+00,  5.2783e-01, -4.1109e-02, -4.4871e-01]])\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_09:26:49] Top-1 correct / Total: 166/400, Top-1 accuracy: 0.415, Top-3 correct / Total: 166/400, Top-3 accuracy: 0.415 time: 203.75796246528625\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_09:26:49] Top-1 correct / Total: 321/400, Top-1 accuracy: 0.8025, Top-3 correct / Total: 321/400, Top-3 accuracy: 0.8025, time: 203.75796246528625\n",
      "\n",
      "Saving current best model in experiments/train_poison_DataFolder_CIFAR10_LIRA_\n",
      "\n",
      "[2024-03-11_09:26:49] Best Clean accuracy: 41.5 Best Backdoor accuracy: 80.25 time: 203.80098509788513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train backdoored model\n",
    "LIRA.train()\n",
    "\n",
    "# Get the poisoned dataset\n",
    "poisoned_train_dataset, poisoned_test_dataset = LIRA.get_poisoned_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
