{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32827\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/32827/Documents/GitHub/BackdoorBox/')\n",
    "import core\n",
    "# import LIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_dataset\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import DatasetFolder, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss,Softmax\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets and follow the default data augmentation in the original paper\n",
    "transform_train = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    train=True,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   29    30    35 ... 49941 49992 49994]\n",
      "[    4     5    32 ... 49993 49998 49999]\n",
      "[    6    13    18 ... 49987 49991 49995]\n",
      "[    9    17    21 ... 49979 49982 49983]\n",
      "[49921 38980 45102 ... 22793 33978 33275]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "trainset.targets = np.array(trainset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(trainset.targets == targets)[0]\n",
    "    print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 1000))\n",
    "idx = idx.astype(int)\n",
    "print(idx)\n",
    "trainset.data = trainset.data[idx]\n",
    "trainset.targets = trainset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_test,\n",
    "    target_transform=None,\n",
    "    train=False,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "testset.targets = np.array(testset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(testset.targets == targets)[0]\n",
    "    # print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 100))\n",
    "idx = idx.astype(int)\n",
    "# print(idx)\n",
    "testset.data = testset.data[idx]\n",
    "testset.targets = testset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(3)\n",
    "    ansatz = RealAmplitudes(3, reps=1)\n",
    "    qc = QuantumCircuit(3)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    parity = lambda x: \"{:b}\".format(x).count(\"1\") % 4  # optional interpret function\n",
    "    output_shape = 4  # parity = 0, 1\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        interpret=parity,\n",
    "        output_shape=output_shape,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self,qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(84,4)  # 1-dimensional output from QNN\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc4 = Linear(4,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "classifier_model = Net(qnn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = {\n",
    "    'device': 'GPU',\n",
    "    'CUDA_VISIBLE_DEVICES': '1',\n",
    "    'GPU_num': 1,\n",
    "\n",
    "    'benign_training': False,\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 8,\n",
    "\n",
    "    'lr': 0.0001,\n",
    "    'lr_atk': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    \n",
    "    'epochs': 10,\n",
    "    'train_epoch': 1,\n",
    "    'cls_test_epoch': 5,\n",
    "\n",
    "\n",
    "    'tune_test_epochs': 1,\n",
    "    'tune_test_lr': 0.0001,\n",
    "    'tune_momentum': 0.9,\n",
    "    'tune_weight_decay': 5e-4,\n",
    "    'tune_test_epoch_interval': 1,\n",
    "\n",
    "    'schedulerC_lambda': 0.1,\n",
    "    'schedulerC_milestones': '50,100,150,200',\n",
    "\n",
    "    'log_iteration_interval': 100,\n",
    "    'test_epoch_interval': 10,\n",
    "    'save_epoch_interval': 10,\n",
    "\n",
    "    'pretrain':\"./models/normal-cifar10_mdl.pt\",\n",
    "    'save_dir': 'experiments',\n",
    "    'experiment_name': 'train_poison_DataFolder_CIFAR10_LIRA'\n",
    "    # 'num_workers' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIRA = core.LIRA(\n",
    "    dataset_name=\"ncifar10\",\n",
    "    train_dataset=trainset,\n",
    "    test_dataset=testset,\n",
    "    model=classifier_model, #core.models.vgg11(num_classes=10), #core.models.ResNet(18),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    y_target=1,\n",
    "    eps=0.001,\n",
    "    alpha=0.5,\n",
    "    tune_test_eps=0.0001,\n",
    "    tune_test_alpha=0.5,\n",
    "    best_threshold=0.1,\n",
    "    schedule=schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain activated\n",
      "This machine has 1 cuda devices, and use 1 of them to train.\n",
      "Total train samples: 4000\n",
      "Total test samples: 400\n",
      "Batch size: 4\n",
      "iteration every epoch: 1000\n",
      "Initial learning rate: 0.0001\n",
      "\n",
      "[2024-03-11_21:02:05] Train [1] Loss: clean 1.3982 poison 7.3508 total 4.3745 Tri 1.4261\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:02:12] Top-1 correct / Total: 157/400, Top-1 accuracy: 0.3925, Top-3 correct / Total: 157/400, Top-3 accuracy: 0.3925 time: 59.01947617530823\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:02:12] Top-1 correct / Total: 332/400, Top-1 accuracy: 0.83, Top-3 correct / Total: 332/400, Top-3 accuracy: 0.83, time: 59.01947617530823\n",
      "\n",
      "[2024-03-11_21:02:31] Train [2] Loss: clean 0.8842 poison 4.2086 total 2.5464 Tri 1.4259\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:02:35] Top-1 correct / Total: 183/400, Top-1 accuracy: 0.4575, Top-3 correct / Total: 183/400, Top-3 accuracy: 0.4575 time: 82.61458230018616\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:02:35] Top-1 correct / Total: 301/400, Top-1 accuracy: 0.7525, Top-3 correct / Total: 301/400, Top-3 accuracy: 0.7525, time: 82.61458230018616\n",
      "\n",
      "[2024-03-11_21:02:52] Train [3] Loss: clean 0.8304 poison 3.7212 total 2.2758 Tri 1.4143\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:02:57] Top-1 correct / Total: 174/400, Top-1 accuracy: 0.435, Top-3 correct / Total: 174/400, Top-3 accuracy: 0.435 time: 103.91767907142639\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:02:57] Top-1 correct / Total: 307/400, Top-1 accuracy: 0.7675, Top-3 correct / Total: 307/400, Top-3 accuracy: 0.7675, time: 103.9186794757843\n",
      "\n",
      "[2024-03-11_21:03:14] Train [4] Loss: clean 0.7947 poison 3.7516 total 2.2732 Tri 1.4066\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:03:20] Top-1 correct / Total: 180/400, Top-1 accuracy: 0.45, Top-3 correct / Total: 180/400, Top-3 accuracy: 0.45 time: 127.18626570701599\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:03:20] Top-1 correct / Total: 299/400, Top-1 accuracy: 0.7475, Top-3 correct / Total: 299/400, Top-3 accuracy: 0.7475, time: 127.18726539611816\n",
      "\n",
      "[2024-03-11_21:03:39] Train [5] Loss: clean 0.7685 poison 3.8412 total 2.3049 Tri 1.4215\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:03:45] Top-1 correct / Total: 163/400, Top-1 accuracy: 0.4075, Top-3 correct / Total: 163/400, Top-3 accuracy: 0.4075 time: 151.8113808631897\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:03:45] Top-1 correct / Total: 322/400, Top-1 accuracy: 0.805, Top-3 correct / Total: 322/400, Top-3 accuracy: 0.805, time: 151.8113808631897\n",
      "\n",
      "[2024-03-11_21:04:04] Train [6] Loss: clean 0.7516 poison 3.7992 total 2.2754 Tri 1.4112\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:04:09] Top-1 correct / Total: 161/400, Top-1 accuracy: 0.4025, Top-3 correct / Total: 161/400, Top-3 accuracy: 0.4025 time: 176.41694951057434\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:04:09] Top-1 correct / Total: 325/400, Top-1 accuracy: 0.8125, Top-3 correct / Total: 325/400, Top-3 accuracy: 0.8125, time: 176.4179491996765\n",
      "\n",
      "[2024-03-11_21:04:29] Train [7] Loss: clean 0.7359 poison 3.8275 total 2.2817 Tri 1.4222\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:04:34] Top-1 correct / Total: 164/400, Top-1 accuracy: 0.41, Top-3 correct / Total: 164/400, Top-3 accuracy: 0.41 time: 201.65240025520325\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:04:34] Top-1 correct / Total: 327/400, Top-1 accuracy: 0.8175, Top-3 correct / Total: 327/400, Top-3 accuracy: 0.8175, time: 201.65340113639832\n",
      "\n",
      "[2024-03-11_21:04:56] Train [8] Loss: clean 0.7254 poison 3.8344 total 2.2799 Tri 1.4185\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:05:02] Top-1 correct / Total: 170/400, Top-1 accuracy: 0.425, Top-3 correct / Total: 170/400, Top-3 accuracy: 0.425 time: 229.06711220741272\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:05:02] Top-1 correct / Total: 312/400, Top-1 accuracy: 0.78, Top-3 correct / Total: 312/400, Top-3 accuracy: 0.78, time: 229.06711220741272\n",
      "\n",
      "[2024-03-11_21:05:22] Train [9] Loss: clean 0.7050 poison 3.9892 total 2.3471 Tri 1.4349\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:05:28] Top-1 correct / Total: 202/400, Top-1 accuracy: 0.505, Top-3 correct / Total: 202/400, Top-3 accuracy: 0.505 time: 254.93222904205322\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:05:28] Top-1 correct / Total: 278/400, Top-1 accuracy: 0.695, Top-3 correct / Total: 278/400, Top-3 accuracy: 0.695, time: 254.93222904205322\n",
      "\n",
      "[2024-03-11_21:05:47] Train [10] Loss: clean 0.7017 poison 3.8255 total 2.2636 Tri 1.4310\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:06:13] Top-1 correct / Total: 193/400, Top-1 accuracy: 0.4825, Top-3 correct / Total: 193/400, Top-3 accuracy: 0.4825 time: 300.05533361434937\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:06:13] Top-1 correct / Total: 293/400, Top-1 accuracy: 0.7325, Top-3 correct / Total: 293/400, Top-3 accuracy: 0.7325, time: 300.05533361434937\n",
      "\n",
      "[2024-03-11_21:06:35] Finetune [1] Loss: clean 1.1911 poison 0.6847 total 0.9379\n",
      "\n",
      "tensor([[ 0.0685,  3.3054, -1.9144, -0.7166],\n",
      "        [ 2.2921,  2.2037, -1.3250, -1.3405],\n",
      "        [ 2.5723,  2.3597, -0.9801, -2.6556],\n",
      "        ...,\n",
      "        [-1.2944,  1.2023, -0.7570,  0.4207],\n",
      "        [-0.9049,  0.5231, -0.2593, -0.0940],\n",
      "        [-0.2672,  0.0231, -0.3269,  0.8727]])\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_21:06:35] Top-1 correct / Total: 162/400, Top-1 accuracy: 0.405, Top-3 correct / Total: 162/400, Top-3 accuracy: 0.405 time: 322.7064366340637\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_21:06:35] Top-1 correct / Total: 327/400, Top-1 accuracy: 0.8175, Top-3 correct / Total: 327/400, Top-3 accuracy: 0.8175, time: 322.70743680000305\n",
      "\n",
      "Saving current best model in experiments/train_poison_DataFolder_CIFAR10_LIRA_\n",
      "\n",
      "[2024-03-11_21:06:36] Best Clean accuracy: 40.5 Best Backdoor accuracy: 81.75 time: 322.76843643188477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train backdoored model\n",
    "LIRA.train()\n",
    "\n",
    "# Get the poisoned dataset\n",
    "poisoned_train_dataset, poisoned_test_dataset = LIRA.get_poisoned_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
