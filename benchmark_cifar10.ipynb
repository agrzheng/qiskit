{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss,Softmax\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32827\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_modify import buildpoison,Datapoison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--trigger_size'], dest='trigger_size', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='Trigger Size (int, default: 5)', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "parser = argparse.ArgumentParser(description='Reproduce the basic backdoor attack in \"Badnets: Identifying vulnerabilities in the machine learning model supply chain\".')\n",
    "parser.add_argument('--dataset', default='CIFAR10', help='Which dataset to use (MNIST or CIFAR10, default: MNIST)')\n",
    "parser.add_argument('--data_path', default='./data/', help='Place to load dataset (default: ./dataset/)')\n",
    "parser.add_argument('--nb_classes', default=10, type=int, help='number of the classification types')\n",
    "# poison settings\n",
    "parser.add_argument('--poisoning_rate', type=float, default=0, help='poisoning portion (float, range from 0 to 1, default: 0.1)')\n",
    "parser.add_argument('--trigger_label', type=int, default=1, help='The NO. of trigger label (int, range from 0 to 10, default: 0)')\n",
    "parser.add_argument('--trigger_path', default=\"./triggers/trigger_10.png\", help='Trigger Path (default: ./triggers/trigger_white.png)')\n",
    "parser.add_argument('--trigger_size', type=int, default=5, help='Trigger Size (int, default: 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(3)\n",
    "    ansatz = RealAmplitudes(3, reps=1)\n",
    "    qc = QuantumCircuit(3)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    parity = lambda x: \"{:b}\".format(x).count(\"1\") % 4  # optional interpret function\n",
    "    output_shape = 4  # parity = 0, 1\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        interpret=parity,\n",
    "        output_shape=output_shape,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "class qnnNet(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(84,3)  # 1-dimensional output from QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc4 = Linear(4,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(84,4)  # 1-dimensional output from QNN\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc4 = Linear(4,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnn = create_qnn()\n",
    "qnnmodel = qnnNet(qnn)\n",
    "qnnmodel.load_state_dict(torch.load(\"./Hybrid-qnn/models/cifar10_qiskitmdl.pt\"))\n",
    "\n",
    "qnn = create_qnn()\n",
    "qnnmodel_pos = qnnNet(qnn)\n",
    "qnnmodel_pos.load_state_dict(torch.load(\"./Hybrid-qnn/models/cifar10_poisonedmdl.pt\"))\n",
    "\n",
    "qnn = create_qnn()\n",
    "qnnmodel_bt = qnnNet(qnn)\n",
    "qnnmodel_bt.load_state_dict(torch.load(\"./Hybrid-qnn/models/qiskit_8bit_final_trojan.pt\"))\n",
    "\n",
    "normalmodel_pos = Net()\n",
    "normalmodel_pos.load_state_dict(torch.load(\"./normalNN/models/normal-cifar10_poisonedmdl.pt\"))\n",
    "\n",
    "normalmodel = Net()\n",
    "normalmodel.load_state_dict(torch.load(\"./normalNN/models/normal-cifar10_mdl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform =  Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Poison 10000 over 10000 samples ( poisoning rate 1.0)\n",
      "Number of the class = 10\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           ) Dataset CIFAR10Poison\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST test data\n",
    "args, unknown = parser.parse_known_args()\n",
    "X_test_clean, X_test_poisoned = buildpoison.build_testset(is_train=False, args=args)\n",
    "\n",
    "X_test_clean.targets = np.array(X_test_clean.targets)\n",
    "X_test_clean.data = np.array(X_test_clean.data)\n",
    "X_test_poisoned.targets = np.array(X_test_poisoned.targets)\n",
    "X_test_poisoned.data = np.array(X_test_poisoned.data)\n",
    "\n",
    "idx_clean = []\n",
    "for targets in range(4):\n",
    "    classes = np.where(X_test_clean.targets == targets)[0]\n",
    "    idx_clean = np.append(idx_clean,random.choices(classes,k = n_samples))\n",
    "idx_poisoned = []\n",
    "for targets in range(4):\n",
    "    classes = np.where(X_test_poisoned.targets == targets)[0]\n",
    "    idx_poisoned = np.append(idx_poisoned,random.choices(classes,k = n_samples))\n",
    "\n",
    "idx_clean = idx_clean.astype(int)\n",
    "idx_poisoned = idx_poisoned.astype(int)\n",
    "\n",
    "X_test_clean.data = X_test_clean.data[idx_clean]\n",
    "X_test_clean.targets = X_test_clean.targets[idx_clean]\n",
    "X_test_poisoned.data = X_test_poisoned.data[idx_poisoned]\n",
    "X_test_poisoned.targets = X_test_poisoned.targets[idx_poisoned]\n",
    "\n",
    "X_test_poisoned.targets = Tensor(X_test_poisoned.targets).long()\n",
    "X_test_clean.targets = Tensor(X_test_clean.targets).long()\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "clean_test_loader = DataLoader(X_test_clean, shuffle=True)\n",
    "poisoned_test_loader = DataLoader(X_test_poisoned, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_test_clean.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN Performance on clean test data:\n",
      "\tLoss: 1.0339\n",
      "\tAccuracy: 72.5%\n",
      "QNN Attack success rate:\n",
      "\tLoss: 4.5777\n",
      "\tAccuracy: 22.9%\n",
      "QNN_Pos Performance on clean test data:\n",
      "\tLoss: 1.0066\n",
      "\tAccuracy: 69.7%\n",
      "QNN_Pos Attack success rate:\n",
      "\tLoss: 0.0228\n",
      "\tAccuracy: 99.6%\n",
      "QNN Performance on clean test data:\n",
      "\tLoss: 1.3253\n",
      "\tAccuracy: 67.0%\n",
      "QNN Attack success rate:\n",
      "\tLoss: 1.7793\n",
      "\tAccuracy: 41.9%\n",
      "CNN_pos Performance on clean test data:\n",
      "\tLoss: 1.2075\n",
      "\tAccuracy: 71.6%\n",
      "CNN_pos Performance on poisoned test data:\n",
      "\tLoss: 0.1431\n",
      "\tAccuracy: 97.0%\n",
      "CNN Performance on clean test data:\n",
      "\tLoss: 1.7755\n",
      "\tAccuracy: 70.2%\n",
      "CNN Performance on poisoned test data:\n",
      "\tLoss: 14.4136\n",
      "\tAccuracy: 23.3%\n"
     ]
    }
   ],
   "source": [
    "qnnmodel.eval()  # set model to evaluation mode\n",
    "loss_func = CrossEntropyLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = qnnmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = qnnmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Attack success rate:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "qnnmodel_pos.eval()  # set model to evaluation mode\n",
    "loss_func = CrossEntropyLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = qnnmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN_Pos Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = qnnmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN_Pos Attack success rate:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "qnnmodel_bt.eval()  # set model to evaluation mode\n",
    "loss_func = CrossEntropyLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = qnnmodel_bt(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = qnnmodel_bt(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Attack success rate:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "normalmodel_pos.eval()  # set model to evaluation mode\n",
    "loss_func = CrossEntropyLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = normalmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN_pos Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = normalmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN_pos Performance on poisoned test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "normalmodel.eval()  # set model to evaluation mode\n",
    "loss_func = CrossEntropyLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = normalmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = normalmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN Performance on poisoned test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / 1 * 100\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
