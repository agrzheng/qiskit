{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32827\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/32827/Documents/GitHub/BackdoorBox/')\n",
    "import core\n",
    "# import LIRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_dataset\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import DatasetFolder, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss,Softmax\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets and follow the default data augmentation in the original paper\n",
    "transform_train = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                        (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    train=True,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   29    30    35 ... 49941 49992 49994]\n",
      "[    4     5    32 ... 49993 49998 49999]\n",
      "[    6    13    18 ... 49987 49991 49995]\n",
      "[    9    17    21 ... 49979 49982 49983]\n",
      "[25350 38419   695 ... 40066 23430 13953]\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "trainset.targets = np.array(trainset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(trainset.targets == targets)[0]\n",
    "    print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 1000))\n",
    "idx = idx.astype(int)\n",
    "print(idx)\n",
    "trainset.data = trainset.data[idx]\n",
    "trainset.targets = trainset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = CIFAR10(\n",
    "    root='../data', # please replace this with path to your dataset\n",
    "    transform=transform_test,\n",
    "    target_transform=None,\n",
    "    train=False,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "testset.targets = np.array(testset.targets).astype('int64')\n",
    "for targets in range(4):\n",
    "    classes = np.where(testset.targets == targets)[0]\n",
    "    # print(classes)\n",
    "    idx = np.append(idx,random.choices(classes,k = 100))\n",
    "idx = idx.astype(int)\n",
    "# print(idx)\n",
    "testset.data = testset.data[idx]\n",
    "testset.targets = testset.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(3)\n",
    "    ansatz = RealAmplitudes(3, reps=1)\n",
    "    qc = QuantumCircuit(3)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    parity = lambda x: \"{:b}\".format(x).count(\"1\") % 4  # optional interpret function\n",
    "    output_shape = 4  # parity = 0, 1\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        interpret=parity,\n",
    "        output_shape=output_shape,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self,qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 6, 5)\n",
    "        self.pool = MaxPool2d(2, 2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.fc1 = Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(84,3)  # 1-dimensional output from QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc4 = Linear(4,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "classifier_model = Net(qnn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = {\n",
    "    'device': 'GPU',\n",
    "    'CUDA_VISIBLE_DEVICES': '1',\n",
    "    'GPU_num': 1,\n",
    "\n",
    "    'benign_training': False,\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 8,\n",
    "\n",
    "    'lr': 0.0001,\n",
    "    'lr_atk': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    \n",
    "    'epochs': 5,\n",
    "    'train_epoch': 1,\n",
    "    'cls_test_epoch': 5,\n",
    "\n",
    "\n",
    "    'tune_test_epochs': 1,\n",
    "    'tune_test_lr': 0.0001,\n",
    "    'tune_momentum': 0.9,\n",
    "    'tune_weight_decay': 5e-4,\n",
    "    'tune_test_epoch_interval': 1,\n",
    "\n",
    "    'schedulerC_lambda': 0.1,\n",
    "    'schedulerC_milestones': '50,100,150,200',\n",
    "\n",
    "    'log_iteration_interval': 100,\n",
    "    'test_epoch_interval': 10,\n",
    "    'save_epoch_interval': 10,\n",
    "\n",
    "    'save_dir': 'experiments',\n",
    "    'experiment_name': 'train_poison_DataFolder_CIFAR10_LIRA',\n",
    "    'pretrain': \"./models/cifar10_qiskitmdl.pt\"\n",
    "    # 'num_workers' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIRA = core.LIRA(\n",
    "    dataset_name=\"cifar10\",\n",
    "    train_dataset=trainset,\n",
    "    test_dataset=testset,\n",
    "    model=classifier_model, #core.models.vgg11(num_classes=10), #core.models.ResNet(18),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    y_target=1,\n",
    "    eps=0.0001,\n",
    "    alpha=0.5,\n",
    "    tune_test_eps=0.0001,\n",
    "    tune_test_alpha=0.5,\n",
    "    best_threshold=0.1,\n",
    "    schedule=schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain activated\n",
      "This machine has 1 cuda devices, and use 1 of them to train.\n",
      "Total train samples: 4000\n",
      "Total test samples: 400\n",
      "Batch size: 4\n",
      "iteration every epoch: 1000\n",
      "Initial learning rate: 0.0001\n",
      "\n",
      "[2024-03-10_21:10:18] Train [1] Loss: clean 1.0290 poison 3.1868 total 2.1079 Tri 1.4332\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-10_21:23:31] Top-1 correct / Total: 183/400, Top-1 accuracy: 0.4575, Top-3 correct / Total: 349/400, Top-3 accuracy: 0.8725 time: 2486.8949267864227\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-10_21:23:31] Top-1 correct / Total: 276/400, Top-1 accuracy: 0.69, Top-3 correct / Total: 397/400, Top-3 accuracy: 0.9925, time: 2486.8959267139435\n",
      "\n",
      "[2024-03-10_21:51:15] Train [2] Loss: clean 0.8476 poison 2.9706 total 1.9091 Tri 1.4184\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-10_22:12:50] Top-1 correct / Total: 175/400, Top-1 accuracy: 0.4375, Top-3 correct / Total: 347/400, Top-3 accuracy: 0.8675 time: 5444.935863494873\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-10_22:12:50] Top-1 correct / Total: 285/400, Top-1 accuracy: 0.7125, Top-3 correct / Total: 398/400, Top-3 accuracy: 0.995, time: 5444.937863349915\n",
      "\n",
      "[2024-03-10_22:52:29] Train [3] Loss: clean 0.8005 poison 2.8667 total 1.8336 Tri 1.4385\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-10_23:06:37] Top-1 correct / Total: 162/400, Top-1 accuracy: 0.405, Top-3 correct / Total: 365/400, Top-3 accuracy: 0.9125 time: 8672.513693094254\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-10_23:06:37] Top-1 correct / Total: 316/400, Top-1 accuracy: 0.79, Top-3 correct / Total: 400/400, Top-3 accuracy: 1.0, time: 8672.514692544937\n",
      "\n",
      "[2024-03-10_23:37:54] Train [4] Loss: clean 0.7853 poison 2.9096 total 1.8475 Tri 1.4273\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-10_23:54:33] Top-1 correct / Total: 175/400, Top-1 accuracy: 0.4375, Top-3 correct / Total: 356/400, Top-3 accuracy: 0.89 time: 11547.935554027557\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-10_23:54:33] Top-1 correct / Total: 280/400, Top-1 accuracy: 0.7, Top-3 correct / Total: 400/400, Top-3 accuracy: 1.0, time: 11547.93655371666\n",
      "\n",
      "[2024-03-11_00:34:33] Train [5] Loss: clean 0.7523 poison 2.9483 total 1.8503 Tri 1.4463\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_01:54:11] Top-1 correct / Total: 163/400, Top-1 accuracy: 0.4075, Top-3 correct / Total: 374/400, Top-3 accuracy: 0.935 time: 18726.562046051025\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_01:54:11] Top-1 correct / Total: 313/400, Top-1 accuracy: 0.7825, Top-3 correct / Total: 400/400, Top-3 accuracy: 1.0, time: 18726.57004880905\n",
      "\n",
      "[2024-03-11_02:05:59] Finetune [1] Loss: clean 1.1917 poison 0.8510 total 1.0214\n",
      "\n",
      "==========Test result on benign test dataset==========\n",
      "[2024-03-11_02:06:10] Top-1 correct / Total: 153/400, Top-1 accuracy: 0.3825, Top-3 correct / Total: 372/400, Top-3 accuracy: 0.93 time: 19444.987859249115\n",
      "\n",
      "==========Test result on poisoned test dataset==========\n",
      "[2024-03-11_02:06:10] Top-1 correct / Total: 334/400, Top-1 accuracy: 0.835, Top-3 correct / Total: 400/400, Top-3 accuracy: 1.0, time: 19444.988859415054\n",
      "\n",
      "Saving current best model in experiments/train_poison_DataFolder_CIFAR10_LIRA_\n",
      "\n",
      "[2024-03-11_02:06:10] Best Clean accuracy: 38.25 Best Backdoor accuracy: 83.5 time: 19445.102858304977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train backdoored model\n",
    "LIRA.train()\n",
    "\n",
    "# Get the poisoned dataset\n",
    "poisoned_train_dataset, poisoned_test_dataset = LIRA.get_poisoned_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
