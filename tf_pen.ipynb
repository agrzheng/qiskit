{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow import keras \n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_modify import buildpoison,Datapoison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--trigger_size'], dest='trigger_size', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='Trigger Size (int, default: 5)', metavar=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "parser = argparse.ArgumentParser(description='Reproduce the basic backdoor attack in \"Badnets: Identifying vulnerabilities in the machine learning model supply chain\".')\n",
    "parser.add_argument('--dataset', default='MNIST', help='Which dataset to use (MNIST or CIFAR10, default: MNIST)')\n",
    "parser.add_argument('--data_path', default='./data/', help='Place to load dataset (default: ./dataset/)')\n",
    "parser.add_argument('--nb_classes', default=10, type=int, help='number of the classification types')\n",
    "# poison settings\n",
    "parser.add_argument('--poisoning_rate', type=float, default=0.1, help='poisoning portion (float, range from 0 to 1, default: 0.1)')\n",
    "parser.add_argument('--trigger_label', type=int, default=1, help='The NO. of trigger label (int, range from 0 to 10, default: 0)')\n",
    "parser.add_argument('--trigger_path', default=\"./triggers/trigger_white.png\", help='Trigger Path (default: ./triggers/trigger_white.png)')\n",
    "parser.add_argument('--trigger_size', type=int, default=5, help='Trigger Size (int, default: 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform =  Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5,), std=(0.5,))\n",
      ")\n",
      "Poison 6000 over 60000 samples ( poisoning rate 0.1)\n",
      "Number of the class = 10\n",
      "Dataset MNISTPoison\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "args, unknown = parser.parse_known_args()\n",
    "X_train, args.nb_classes = buildpoison.build_poisoned_training_set(is_train=True, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):  \n",
    "       \n",
    "    depth = 3**3                       # 10 classes + 6 zeros for padding\n",
    "    indices = labels.astype(np.int32)    \n",
    "    one_hot_labels = np.eye(depth)[indices].astype(np.float32) \n",
    "    \n",
    "    return one_hot_labels\n",
    "\n",
    "# one-hot encoded labels, each label of length cutoff dimension**2\n",
    "y_train = one_hot(X_train.targets.numpy())\n",
    "X_train = X_train.data.numpy()\n",
    "\n",
    "# using only 600 samples for training in this experiment\n",
    "n_samples = 600\n",
    "test_samples = 100\n",
    "X_train, y_train= X_train[:n_samples], y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 22)                726       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111542 (435.71 KB)\n",
      "Trainable params: 111542 (435.71 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_floatx('float32')\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "                                 layers.Flatten(input_shape = (28,28)),\n",
    "                                 layers.Dense(128, activation =\"elu\"),\n",
    "                                 layers.Dense(64, activation =\"elu\"),\n",
    "                                 layers.Dense(32, activation =\"elu\"),\n",
    "                                 layers.Dense(22, activation =\"elu\") \n",
    "                                ])\n",
    "\n",
    "# More than a million parameters for the classical circuit\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(x):\n",
    "    qml.Squeezing(x[0], 0.0, wires=0)\n",
    "    qml.Squeezing(x[1], 0.0, wires=1)\n",
    "    qml.Squeezing(x[2], 0.0, wires=2)\n",
    "    \n",
    "    qml.Beamsplitter(x[3], x[4], wires=[0,1])\n",
    "    qml.Beamsplitter(x[5], x[6], wires=[1,2])\n",
    "\n",
    "    qml.Rotation(x[7], wires=0)\n",
    "    qml.Rotation(x[8], wires=1)\n",
    "    qml.Rotation(x[9], wires=2)\n",
    "   \n",
    "    qml.Displacement(x[10], 0.0, wires=0)\n",
    "    qml.Displacement(x[11], 0.0, wires=1)\n",
    "    qml.Displacement(x[12], 0.0, wires=2)\n",
    " \n",
    "    qml.Kerr(x[13], wires=0)\n",
    "    qml.Kerr(x[14], wires=1)\n",
    "    qml.Kerr(x[15], wires=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(v):\n",
    "    qml.Beamsplitter(v[0], v[1], wires=[0,1])\n",
    "    qml.Beamsplitter(v[2], v[3], wires=[1,2])\n",
    "\n",
    "    qml.Rotation(v[4], wires=0)\n",
    "    qml.Rotation(v[5], wires=1)\n",
    "    qml.Rotation(v[6], wires=2)\n",
    "\n",
    "    qml.Squeezing(v[7], 0.0, wires=0)\n",
    "    qml.Squeezing(v[8], 0.0, wires=1)\n",
    "    qml.Squeezing(v[9], 0.0, wires=2)\n",
    "    \n",
    "    qml.Beamsplitter(v[10], v[11], wires=[0,1])\n",
    "    qml.Beamsplitter(v[12], v[13], wires=[1,2])\n",
    "\n",
    "    qml.Rotation(v[14], wires=0)\n",
    "    qml.Rotation(v[15], wires=1)\n",
    "    qml.Rotation(v[16], wires=2)\n",
    "\n",
    "    qml.Displacement(v[17], 0.0, wires=0)\n",
    "    qml.Displacement(v[18], 0.0, wires=1)\n",
    "    qml.Displacement(v[19], 0.0, wires=2)\n",
    "\n",
    "    qml.Kerr(v[20], wires=0)\n",
    "    qml.Kerr(v[21], wires=1)\n",
    "    qml.Kerr(v[22], wires=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layers, modes, active_sd=0.0001, passive_sd=0.1):\n",
    "    \n",
    "    M = 4+3  # Number of interferometer parameters: 2 2-parameter beamsplitters + 3 rotations\n",
    "\n",
    "    int1_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    s_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    int2_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    dr_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    k_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "\n",
    "    weights = tf.concat([int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "    weights = tf.Variable(weights)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modes = 3\n",
    "num_basis = 3\n",
    "\n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_modes, cutoff_dim=num_basis) \n",
    "\n",
    "@qml.qnode(dev, interface=\"tf\")\n",
    "def quantum_nn(inputs, var):\n",
    "    init_layer(inputs)            # Encode input x into quantum state\n",
    "\n",
    "    for v in var:                 # iterative quantum layers\n",
    "        layer(v)\n",
    "\n",
    "    return qml.probs(wires=[0, 1, 2])  # Measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "\n",
    "# initialize weights for quantum layers\n",
    "weights = init_weights(num_layers, num_modes)\n",
    "\n",
    "# Convert the quantum layer to a Keras layer\n",
    "shape_tup = weights.shape\n",
    "weight_shapes = {'var': shape_tup}\n",
    "qlayer = qml.qnn.KerasLayer(quantum_nn, weight_shapes, output_dim = 4)\n",
    "\n",
    "# Add to the classical sequential model\n",
    "model.add(qlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 22)                726       \n",
      "                                                                 \n",
      " keras_layer_1 (KerasLayer)  (None, 4)                 92        \n",
      "                                                                 \n",
      " keras_layer_2 (KerasLayer)  (None, 4)                 0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111634 (436.07 KB)\n",
      "Trainable params: 111634 (436.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(lr = 0.03)\n",
    "model.compile(opt, loss = 'categorical_crossentropy', metrics =['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\ncannot import name 'should_record' from 'tensorflow.python.eager.tape' (c:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\tape.py)\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(64, 22), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\qnn\\keras.py:302\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     reconstructor \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39munstack(inputs):\n\u001b[1;32m--> 302\u001b[0m         reconstructor\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_qnode(inputs)\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\qnn\\keras.py:305\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         reconstructor\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x))\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mstack(reconstructor)\n\u001b[1;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\qnn\\keras.py:320\u001b[0m, in \u001b[0;36mKerasLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluates a QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    316\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m w \u001b[38;5;28;01mfor\u001b[39;00m k, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    319\u001b[0m }\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\qnode.py:842\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m         set_shots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_device, override_shots)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn)()\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[1;32m--> 842\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    845\u001b[0m using_custom_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__delitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    849\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\qnode.py:755\u001b[0m, in \u001b[0;36mQNode.construct\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39m_qfunc_output\n\u001b[0;32m    754\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trainable_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output, qml\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    758\u001b[0m     measurement_processes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mmeasurements)\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:151\u001b[0m, in \u001b[0;36mmulti_dispatch.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m interface \u001b[38;5;241m=\u001b[39m interface \u001b[38;5;129;01mor\u001b[39;00m get_interface(\u001b[38;5;241m*\u001b[39mdispatch_args)\n\u001b[0;32m    149\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlike\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m interface\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:434\u001b[0m, in \u001b[0;36mget_trainable_indices\u001b[1;34m(values, like)\u001b[0m\n\u001b[0;32m    431\u001b[0m         trainable \u001b[38;5;241m=\u001b[39m requires_grad\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlike\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    435\u001b[0m         trainable_params\u001b[38;5;241m.\u001b[39madd(idx)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainable_params\n",
      "File \u001b[1;32mc:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pennylane\\math\\utils.py:458\u001b[0m, in \u001b[0;36mrequires_grad\u001b[1;34m(tensor, interface)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m should_record_backprop\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 458\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m should_record \u001b[38;5;28;01mas\u001b[39;00m should_record_backprop\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m should_record_backprop([tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(tensor)])\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interface \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mImportError\u001b[0m: Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\ncannot import name 'should_record' from 'tensorflow.python.eager.tape' (c:\\Users\\32827\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\tape.py)\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(64, 22), dtype=float32)"
     ]
    }
   ],
   "source": [
    "hybrid = model.fit(X_train, \n",
    "                   y_train,\n",
    "                   epochs = 100,\n",
    "                   batch_size = 64,\n",
    "                   shuffle = True, \n",
    "                   validation_data = (X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
