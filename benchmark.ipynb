{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss,Softmax\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32827\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_modify import buildpoison,Datapoison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--trigger_size'], dest='trigger_size', nargs=None, const=None, default=5, type=<class 'int'>, choices=None, required=False, help='Trigger Size (int, default: 5)', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "parser = argparse.ArgumentParser(description='Reproduce the basic backdoor attack in \"Badnets: Identifying vulnerabilities in the machine learning model supply chain\".')\n",
    "parser.add_argument('--dataset', default='MNIST', help='Which dataset to use (MNIST or CIFAR10, default: MNIST)')\n",
    "parser.add_argument('--data_path', default='./data/', help='Place to load dataset (default: ./dataset/)')\n",
    "parser.add_argument('--nb_classes', default=10, type=int, help='number of the classification types')\n",
    "# poison settings\n",
    "parser.add_argument('--poisoning_rate', type=float, default=0.1, help='poisoning portion (float, range from 0 to 1, default: 0.1)')\n",
    "parser.add_argument('--trigger_label', type=int, default=1, help='The NO. of trigger label (int, range from 0 to 10, default: 0)')\n",
    "parser.add_argument('--trigger_path', default=\"./triggers/trigger_white.png\", help='Trigger Path (default: ./triggers/trigger_white.png)')\n",
    "parser.add_argument('--trigger_size', type=int, default=5, help='Trigger Size (int, default: 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform =  Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5,), std=(0.5,))\n",
      ")\n",
      "Poison 10000 over 10000 samples ( poisoning rate 1.0)\n",
      "Number of the class = 10\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           ) Dataset MNISTPoison\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "args, unknown = parser.parse_known_args()\n",
    "X_test_clean, X_test_poisoned = buildpoison.build_testset(is_train=False, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "batch_size = 10\n",
    "\n",
    "idx_clean = []\n",
    "for targets in range(10):\n",
    "    idx_clean = np.append(idx_clean,np.where(X_test_clean.targets == targets)[0][:n_samples])\n",
    "idx_poisoned = []\n",
    "for targets in range(10):\n",
    "    idx_poisoned = np.append(idx_poisoned,np.where(X_test_poisoned.targets == targets)[0][:n_samples])\n",
    "X_test_clean.data = X_test_clean.data[idx_clean]\n",
    "X_test_clean.targets = X_test_clean.targets[idx_clean]\n",
    "X_test_poisoned.data = X_test_poisoned.data[idx_poisoned]\n",
    "X_test_poisoned.targets = X_test_poisoned.targets[idx_poisoned]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "clean_test_loader = DataLoader(X_test_clean, batch_size=batch_size, shuffle=True)\n",
    "poisoned_test_loader = DataLoader(X_test_poisoned, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(4)\n",
    "    ansatz = RealAmplitudes(4, reps=1)\n",
    "    qc = QuantumCircuit(4)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    parity = lambda x: \"{:b}\".format(x).count(\"1\") % 10  # optional interpret function\n",
    "    output_shape = 10  # parity = 0, 1\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        interpret=parity,\n",
    "        output_shape=output_shape,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "class qnnNet(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = Conv2d(10, 20, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(320, 50)\n",
    "        self.fc2 = Linear(50, 4)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(10,10)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = Conv2d(10, 20, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(320, 50)\n",
    "        self.fc2 = Linear(50, 10)  # 2-dimensional input to QNN\n",
    "        self.fc3 = Linear(10,10)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnn = create_qnn()\n",
    "qnnmodel = qnnNet(qnn)\n",
    "qnnmodel.load_state_dict(torch.load(\"mnist_qiskitmdl.pt\"))\n",
    "\n",
    "qnn = create_qnn()\n",
    "qnnmodel_pos = qnnNet(qnn)\n",
    "qnnmodel_pos.load_state_dict(torch.load(\"mnist_poisonedmdl.pt\"))\n",
    "\n",
    "normalmodel_pos = Net()\n",
    "normalmodel_pos.load_state_dict(torch.load(\"normal-mnist_poisonedmdl.pt\"))\n",
    "\n",
    "normalmodel = Net()\n",
    "normalmodel.load_state_dict(torch.load(\"normal-mnist_mdl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNN Performance on clean test data:\n",
      "\tLoss: 0.5356\n",
      "\tAccuracy: 88.4%\n",
      "QNN Attack success rate:\n",
      "\tLoss: 8.4256\n",
      "\tAccuracy: 10.1%\n",
      "QNN_Pos Performance on clean test data:\n",
      "\tLoss: 0.6536\n",
      "\tAccuracy: 82.6%\n",
      "QNN_Pos Attack success rate:\n",
      "\tLoss: 0.1813\n",
      "\tAccuracy: 99.3%\n",
      "CNN Performance on clean test data:\n",
      "\tLoss: 0.3281\n",
      "\tAccuracy: 94.5%\n",
      "CNN Performance on poisoned test data:\n",
      "\tLoss: 28.2464\n",
      "\tAccuracy: 10.1%\n",
      "CNN_pos Performance on clean test data:\n",
      "\tLoss: 0.0737\n",
      "\tAccuracy: 97.5%\n",
      "CNN_pos Performance on poisoned test data:\n",
      "\tLoss: 0.0047\n",
      "\tAccuracy: 99.8%\n"
     ]
    }
   ],
   "source": [
    "qnnmodel.eval()  # set model to evaluation mode\n",
    "loss_func = NLLLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = qnnmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = qnnmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN Attack success rate:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "qnnmodel_pos.eval()  # set model to evaluation mode\n",
    "loss_func = NLLLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = qnnmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN_Pos Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = qnnmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"QNN_Pos Attack success rate:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "normalmodel.eval()  # set model to evaluation mode\n",
    "loss_func = NLLLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = normalmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = normalmodel(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN Performance on poisoned test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "\n",
    "normalmodel_pos.eval()  # set model to evaluation mode\n",
    "loss_func = NLLLoss()\n",
    "with no_grad():\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(clean_test_loader):\n",
    "        output = normalmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN_pos Performance on clean test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(clean_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )\n",
    "    total_loss = []\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(poisoned_test_loader):\n",
    "        output = normalmodel_pos(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"CNN_pos Performance on poisoned test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(poisoned_test_loader) / batch_size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
